# CODE GUIDE

ë§ˆì§€ë§‰ ìˆ˜ì • ì¼ì: README
ìƒíƒœ: ğŸ“ê²Œì‹œíŒ
ì‘ì„±ì¼ì‹œ: 2020ë…„ 11ì›” 2ì¼ ì˜¤ì „ 11:53

## ì‹œì‘ì— ì•ì„œ

 ì´ í”„ë¡œì íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ 2ê°œì˜ python íŒŒì¼ (run_websocket_server(0.2.3).py, run_websocket_client(0.2.3).py**)**ë¡œ êµ¬ì„±ë˜ì–´ìˆìŠµë‹ˆë‹¤. ë‘ íŒŒì¼ì€ ê°ê° ë¼ì¦ˆë² ë¦¬íŒŒì´ì™€ ì»´í“¨í„°ì— ë‹¤ìš´ë¡œë“œë˜ì–´ìˆì–´ì•¼ í•˜ë©° ì„œë²„ë¥¼ êµ¬ì„± ë° êµ¬ë™í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì—­í•  ë° ì‚¬ìš©ë²•ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ '[ì´ ê³³](https://www.notion.so/README-76afc5f599944e26929750dfd104106b)'ì„ ì°¸ì¡°í•´ ì£¼ì‹­ì‹œì˜¤. ë³¸ ë¬¸ì„œì—ì„œëŠ” í–¥í›„ ìœ ì§€ë³´ìˆ˜ë¥¼ ìœ„í•´ íŒŒì´ì¬ íŒŒì¼ì˜ ì½”ë“œë§Œì„ ê°„ëµí•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. 

# run_websocket_server(0.2.3).py

### ì—­í• 

âœ”ï¸ ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì‹¤í–‰í•˜ë©°  ì¤‘ì•™ ì„œë²„ë¡œë¶€í„° ì»¤ë§¨ë“œë¥¼ ìˆ˜ì‹ í•˜ëŠ” ì„œë²„ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤.

âœ”ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì„ í† ëŒ€ë¡œ ìˆ˜ì‹ í•œ ì»¤ë§¨ë“œì— ë”°ë¼ ì •í•´ì§„ ë™ì‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ì½”ë“œ

1. **def : start_proc**

```python
def start_proc(participant, kwargs):  # pragma: no cover
    """ helper function for spinning up a websocket participant """

    def target():
        server = participant(**kwargs)
        server.start()

    p = Process(target=target)
    p.start()
    return p
```

- ë§¤ê°œë³€ìˆ˜ participant ì—ëŠ” syft ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ WebsocketServerWorker í•¨ìˆ˜ê°€ ì£¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.
- ë§¤ê°œë³€ìˆ˜ kwargs ì—ëŠ” íŒŒì¼ì„ ì‹¤í–‰í•  ë•Œ ë„£ì€ ì¸ìê°’ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.
- ë‘ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ í† ëŒ€ë¡œ ì„œë²„ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤. multiprocess ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Processs í•¨ìˆ˜ë¥¼ ì´ìš©í•œ ì“°ë ˆë”©ì„ ì´ìš©í•©ë‹ˆë‹¤.

**2. part : parser** 

```python
parser = argparse.ArgumentParser(description="Run websocket server worker.")
parser.add_argument(
    "--port", "-p", type=int, help="port number of the websocket server worker, e.g. --port 8777"
)
parser.add_argument("--host", type=str, default="localhost", help="host for the connection")
parser.add_argument(
    "--id", type=str, help="name (id) of the websocket server worker, e.g. --id alice"
)
parser.add_argument(
    "--verbose",
    "-v",
    action="store_true",
    help="if set, websocket server worker will be started in verbose mode",
)

args = parser.parse_args()
```

- íŒŒì¼ì„ ì‹¤í–‰í•  ë•Œ ê°€ëŠ¥í•œ ì˜µì…˜(argument)ì— ëŒ€í•´ ì •ì˜í•©ë‹ˆë‹¤.
- port, host(ì•„ì´í”¼ ì£¼ì†Œ), id, verbose 4ê°œì˜ ì¸ìê°€ ì¡´ì¬í•©ë‹ˆë‹¤.

**3. part : main**

```python
kwargs = {
    "id": args.id,
    "host": args.host,
    "port": args.port,
    "hook": hook,
    "verbose": args.verbose,
}
server = start_proc(WebsocketServerWorker, kwargs)
```

- ì‹¤í–‰ì‹œ ë°›ì€ ì¸ìë¥¼ í† ëŒ€ë¡œ [start_proc]()ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

# FL_ECG.py

### ì—­í• 

âœ”ï¸ ì¤‘ì•™ ì¥ì¹˜(ë°ìŠ¤í¬í†±, ë…¸íŠ¸ë¶)ì— ì¡´ì¬í•˜ë©° ì‹¤í–‰ ì‹œ ë¼ì¦ˆë² ë¦¬íŒŒì´ê°€ êµ¬ë™ì¤‘ì¸ ì„œë²„ì— ì—°ê²°í•©ë‹ˆë‹¤.

âœ”ï¸ ê° ë¼ì¦ˆë² ë¦¬íŒŒì´ì— FLì„ ìœ„í•œ ì»¤ë§¨ë“œë¥¼ ì†¡ì‹ í•©ë‹ˆë‹¤. 

âœ”ï¸ ë¼ì¦ˆë² ë¦¬íŒŒì´ë¡œë¶€í„° ìˆ˜ì‹ í•œ ëª¨ë¸ì„ í•©ì‚°, ì²˜ë¦¬í•œ í›„ ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ì„ íšŒì‹ í•©ë‹ˆë‹¤. 

 

### ì½”ë“œ

1. **class : ë„¤íŠ¸ì›Œí¬**

```python
import torch.nn as nn
import torch.nn.functional as f

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4 * 4 * 50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = f.relu(self.conv1(x))
        x = f.max_pool2d(x, 2, 2)
        x = f.relu(self.conv2(x))
        x = f.max_pool2d(x, 2, 2)
        x = x.view(-1, 4 * 4 * 50)
        x = f.relu(self.fc1(x))
        x = self.fc2(x)
        return f.log_softmax(x, dim=1)
```

- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë„¤íŠ¸ì›Œí¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
- nn ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì¶”ìƒí™”ëœ Module í´ë˜ìŠ¤ë¥¼ ìƒì†í•©ë‹ˆë‹¤.
- nn ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ functional ì—ì„œ relu, poolê³¼ ê°™ì€ ë ˆì´ì–´ í”„ë¦¬ì…‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**2. def : train_on_batches**

[ë§¤ê°œë³€ìˆ˜](https://www.notion.so/eb6a24eeb8f74be79a5990af8ea2960d)

```python
import torch.optim as optim

def train_on_batches(worker, batches, model_in, device, lr):
    """Train the model on the worker on the provided batches
    Args:
        worker(syft.workers.BaseWorker): worker on which the
        training will be executed
        batches: batches of data of this worker
        model_in: machine learning model, training will be done on a copy
        device (torch.device): where to run the training
        lr: learning rate of the training steps
    Returns:
        model, loss: obtained model and loss after training
    """
    model = model_in.copy()
    optimizer = optim.SGD(model.parameters(), lr=lr)  # TODO momentum is not supported at the moment

    model.train()
    model.send(worker)
    loss_local = False
```

- optimizerì— ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ì˜µí‹°ë§ˆì´ì €ë¥¼ ì„ íƒí•˜ê³  ëª¨ë¸ì„ ì—°ê²° í•œ í›„ í•™ìŠµë¥ ì„ ì •í•©ë‹ˆë‹¤.
- train() í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.

```python
 for batch_idx, (data, target) in enumerate(batches):
        loss_local = False
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = f.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % LOG_INTERVAL == 0:
            loss = loss.get()  # <-- NEW: get the loss back
            loss_local = True
            logger.debug(
                "Train Worker {}: [{}/{} ({:.0f}%)]\tLoss: {:.6f}".format(
                    worker.id,
                    batch_idx,
                    len(batches),
                    100.0 * batch_idx / len(batches),
                    loss.item(),
                )
            )

    if not loss_local:
        loss = loss.get()  # <-- NEW: get the loss back
    model.get()  # <-- NEW: get the model back
    return model, loss
```

- ë°›ì•„ì˜¨ ë°°ì¹˜ ë°ì´í„°ì…‹ì„ ë””ë°”ì´ìŠ¤ë¡œ ë³´ëƒ…ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ë°ì´í„°ì™€ íƒ€ê²Ÿìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
- 

**3. def : get_next_batches**

[ë§¤ê°œë³€ìˆ˜](https://www.notion.so/c813c3e10fe64a1cb751913eaf791ece)

```python
def get_next_batches(fdataloader: sy.FederatedDataLoader, nr_batches: int):
    """retrieve next nr_batches of the federated data loader and group
    the batches by worker
    Args:
        fdataloader (sy.FederatedDataLoader): federated data loader
        over which the function will iterate
        nr_batches (int): number of batches (per worker) to retrieve
    Returns:
        Dict[syft.workers.BaseWorker, List[batches]]
    """
    batches = {}
    for worker_id in fdataloader.workers:
        worker = fdataloader.federated_dataset.datasets[worker_id].location
        batches[worker] = []
    try:
        for i in range(nr_batches):
            next_batches = next(fdataloader)
            for worker in next_batches:
                batches[worker].append(next_batches[worker])
    except StopIteration:
        pass
    return batches
```

- 

**4. def : train** 

[ë§¤ê°œë³€ìˆ˜](https://www.notion.so/53f0bf10a6304d9097270f2dd6931e30)

```python
def train(
    model, device, federated_train_loader, lr, federate_after_n_batches, abort_after_one=False
):
    model.train()

    nr_batches = federate_after_n_batches

    models = {}
    loss_values = {}

    iter(federated_train_loader)  # initialize iterators
    batches = get_next_batches(federated_train_loader, nr_batches)
    counter = 0

    while True:
        logger.debug(
            "Starting training round, batches [{}, {}]".format(counter, counter + nr_batches)
        )
        data_for_all_workers = True
        for worker in batches:
            curr_batches = batches[worker]
            if curr_batches:
                models[worker], loss_values[worker] = train_on_batches(
                    worker, curr_batches, model, device, lr
                )
            else:
                data_for_all_workers = False
        counter += nr_batches
        if not data_for_all_workers:
            logger.debug("At least one worker ran out of data, stopping.")
            break

        model = utils.federated_avg(models)
        batches = get_next_batches(federated_train_loader, nr_batches)
        if abort_after_one:
            break
    return model
```

- ëª¨ë¸ì„ íŠ¸ë ˆì´ë‹í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. model.train() ì— ì‚¬ìš©ë˜ëŠ” íŠ¸ë ˆì´ë‹ ë©”ì„œë“œì™€ëŠ” ë³„ê°œì…ë‹ˆë‹¤.
- batches ë³€ìˆ˜ì—ëŠ” get_next_batches í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ë¯¸ë¦¬ ì •í•œ ë°°ì¹˜ ìˆ˜ ë§Œí¼ì˜ ë°ì´í„°ì…‹ì„ ë°›ì•„ì˜µë‹ˆë‹¤.
- 

**5. def : test**

[ë§¤ê°œë³€ìˆ˜](https://www.notion.so/f73e2c70b084411584664abb93c0cedf)

```python
def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += f.nll_loss(output, target, reduction="sum").item()  # sum up batch loss
            pred = output.argmax(1, keepdim=True)  # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    logger.debug("\n")
    accuracy = 100.0 * correct / len(test_loader.dataset)
    logger.info(
        "Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n".format(
            test_loss, correct, len(test_loader.dataset), accuracy
        )
    )
```

**6. def : define_and_get_arguments**

[ë§¤ê°œë³€ìˆ˜](https://www.notion.so/ee9ca83e4fc54910ab46cafdade2ce86)

```python
def define_and_get_arguments(args=sys.argv[1:]):
    parser = argparse.ArgumentParser(
        description="Run federated learning using websocket client workers."
    )
    parser.add_argument("--batch_size", type=int, default=64, help="batch size of the training")
    parser.add_argument(
        "--test_batch_size", type=int, default=1000, help="batch size used for the test data"
    )
    parser.add_argument("--epochs", type=int, default=2, help="number of epochs to train")
    parser.add_argument(
        "--federate_after_n_batches",
        type=int,
        default=50,        help="number of training steps performed on each remote worker " "before averaging",
    )
    parser.add_argument("--lr", type=float, default=0.01, help="learning rate")
    parser.add_argument("--cuda", action="store_true", help="use cuda")
    parser.add_argument("--seed", type=int, default=1, help="seed used for randomization")
    parser.add_argument("--save_model", action="store_true", help="if set, model will be saved")
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="if set, websocket client workers will " "be started in verbose mode",
    )
    parser.add_argument(
        "--use_virtual", action="store_true", help="if set, virtual workers will be used"
    )

    args = parser.parse_args(args=args)
    return args
```

**7. def : main**

*ë§¤ê°œë³€ìˆ˜ ì—†ìŒ*

```python
def main():
    args = define_and_get_arguments()

    hook = sy.TorchHook(torch)

    # ê°€ìƒì‘ì—…ì(ì‹œë®¬ë ˆì´ì…˜) ì‚¬ìš©ì‹œ ì´ê³³ìœ¼ë¡œ ë¶„ê¸°
    if args.use_virtual:
        alice = VirtualWorker(id="alice", hook=hook, verbose=args.verbose)
        bob = VirtualWorker(id="bob", hook=hook, verbose=args.verbose)
        charlie = VirtualWorker(id="charlie", hook=hook, verbose=args.verbose)
    # ì›¹ì†Œì¼“ì‘ì—…ì ì‚¬ìš©ì‹œ ì´ê³³ìœ¼ë¡œ ë¶„ê¸°
    else:
        a_kwargs_websocket = {"host": "192.168.0.52", "hook": hook}
        b_kwargs_websocket = {"host": "192.168.0.53", "hook": hook}
        c_kwargs_websocket = {"host": "192.168.0.54", "hook": hook}

        baseport = 10002
        alice = WebsocketClientWorker(id="alice", port=baseport, **a_kwargs_websocket)
        bob = WebsocketClientWorker(id="bob", port=baseport, **b_kwargs_websocket)
        charlie = WebsocketClientWorker(id="charlie", port=baseport, **c_kwargs_websocket)

		# ê°ì²´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ìŒ
    workers = [alice, bob, charlie]

		# ì¿ ë‹¤ ì‚¬ìš© ì—¬ë¶€
    use_cuda = args.cuda and torch.cuda.is_available()
    device = torch.device("cuda" if use_cuda else "cpu")
    kwargs = {"num_workers": 1, "pin_memory": True} if use_cuda else {}

		# ëœë¤ ì‹œë“œ ì„¤ì •
    torch.manual_seed(args.seed)
```

- [define_and_get_arguments]()() ë¥¼ ì´ìš©í•˜ì—¬ ì‹¤í–‰ ì˜µì…˜ì„ ë°›ì•„ì˜µë‹ˆë‹¤.
- use_virtual ì˜µì…˜ì„ ì‹¤í–‰í–ˆì„ ê²½ìš° ì›¹ì†Œì¼“ì„ ì´ìš©í•˜ì§€ ì•Šê³  ê°€ìƒ ì›Œì»¤ë¡œ ì‹œë®¬ë ˆì´ì…˜ í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ ë¼ì¦ˆë² ë¦¬ íŒŒì´ì— ì—°ê²°í•˜ì—¬ ì‹¤í–‰í•˜ê¸° ì „ **ê°€ìƒ ì›Œì»¤ ì‹œë®¬ë ˆì´ì…˜ì„ ì´ìš©í•´ í…ŒìŠ¤íŠ¸ ì‹œê°„ì„ ë‹¨ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤**.
- use_virtualì„ ë”°ë¡œ ì„¤ì •í•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì›¹ì†Œì¼“ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì´ ê²½ìš° kwargs_websocketì—ëŠ”  ë¼ì¦ˆë² ë¦¬íŒŒì´ì˜ IP, hookì´ ì£¼ì–´ì§‘ë‹ˆë‹¤. ê·¸ í›„, WebsocketClientWorkerë¥¼ ì´ìš©í•˜ì—¬ ê° IDì— ì›Œì»¤ ê°ì²´ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
- ë”±íˆ ìˆ˜ì •í•  ì¼ì´ ì—†ëŠ” íŒŒíŠ¸ì…ë‹ˆë‹¤.

```python
  federated_train_loader = sy.FederatedDataLoader(
        datasets.MNIST(
            "../data",
            train=True,
            download=True,
            transform=transforms.Compose(
                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]
            ),
        ).federate(tuple(workers)),
        batch_size=args.batch_size,
        shuffle=True,
        iter_per_worker=True,
        **kwargs,
    )

    test_loader = torch.utils.data.DataLoader(
        datasets.MNIST(
            "../data",
            train=False,
            transform=transforms.Compose(
                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]
            ),
        ),
        batch_size=args.test_batch_size,
        shuffle=True,
        **kwargs,
    )

    model = Net().to(device)

    for epoch in range(1, args.epochs + 1):
				# output : 2020-11-05 15:07:04,953 INFO run_websocket_client(0.2.3).py(l:268) - Starting epoch 1/2
        logger.info("Starting epoch %s/%s", epoch, args.epochs)
        model = train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)
        test(model, device, test_loader)

    if args.save_model:
        torch.save(model.state_dict(), "mnist_cnn.pt")
```

- federated_train_loaderëŠ” ë¶ˆëŸ¬ì˜¨ datasetsì„ Federated Learningì´ ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë§Œë“­ë‹ˆë‹¤.
- [FederateDataloader]()ëŠ” Federate Learningì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ëª…ë ¹ì–´ë“¤ì´ ëª¨ì—¬ìˆëŠ” ê°ì²´ì…ë‹ˆë‹¤. ë°˜ë³µìë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ê·¸ ì „ì— ê° ì›Œì»¤ì—ê²Œ ë°ì´í„°ë¥¼ ë¶„ë°°í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜  federated(tuple(workers))ë¥¼ ì´ìš©í•©ë‹ˆë‹¤.
- ì´ì œ args.epochsì— ëª…ì‹œëœ ìˆ˜ë§Œí¼ í•™ìŠµì„ ë°˜ë³µí•©ë‹ˆë‹¤. ì´ epochëŠ” ì¤‘ì•™ ì„œë²„ì—ì„œ ëª¨ë¸ì„ ì§‘ê³„í•˜ëŠ” epochì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 2ì…ë‹ˆë‹¤.

**8. part : main**

```python
if __name__ == "__main__":
    FORMAT = "%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s"
    LOG_LEVEL = logging.DEBUG
    logging.basicConfig(format=FORMAT, level=LOG_LEVEL)

    websockets_logger = logging.getLogger("websockets")
    websockets_logger.setLevel(logging.DEBUG)
    websockets_logger.addHandler(logging.StreamHandler())

    main()
```

- ë³„ê±´ ì—†ê³  ë¡œê¹… ë©”ì‹œì§€ ì„¤ì •ê³¼ ë©”ì¸ í•¨ìˆ˜ ì§„ì…í•˜ëŠ” ë‘ê°€ì§€ íŒŒíŠ¸ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.
- getLoggerë¥¼ ì´ìš©í•´ websocketsë¼ëŠ” ë¡œê±°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. setLevelì„ ì´ìš©í•´ DEBUG ë ˆë²¨ ìœ„ì˜ ë ˆë²¨ì€ ëª¨ë‘ í”„ë¦°íŠ¸í•©ë‹ˆë‹¤. (ë¡œê±° ë ˆë²¨ì€ DEBUG, INFO,  WARNING, ERROR, CRITICAL 5ê°œê°€ ì¡´ì¬í•©ë‹ˆë‹¤.)
- addHandlerë¥¼ ì´ìš©í•´ ì½˜ì†”ì°½ì— ë¡œê·¸ê°€ ì¶œë ¥ë˜ê²Œë” ì„¤ì •í•©ë‹ˆë‹¤. íŒŒì¼,DB,ì†Œì¼“,í ë“±ì„ í†µí•´ ì¶œë ¥í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
- ë¡œê¹…ì— ëŒ€í•´ ì°¸ê³ í• ë§Œí•œ ë¸”ë¡œê·¸ ê¸€ â¬‡ï¸

[íŒŒì´ì¬ ë¡œê¹…ì˜ ëª¨ë“ ê²ƒ](https://hamait.tistory.com/880)

- ì´í›„ [ë©”ì¸í•¨ìˆ˜ì—]() ì§„ì…í•©ë‹ˆë‹¤.

### ì°¸ê³ í•  í•¨ìˆ˜

- **FederatedDataLoader**

    ```python
    class FederatedDataLoader(object):
        """
        Data loader. Combines a dataset and a sampler, and provides
        single or several iterators over the dataset.
        Arguments:
            federated_dataset (FederatedDataset): dataset from which to load the data.
            batch_size (int, optional): how many samples per batch to load
                (default: ``1``).
            shuffle (bool, optional): set to ``True`` to have the data reshuffled
                at every epoch (default: ``False``).
            collate_fn (callable, optional): merges a list of samples to form a mini-batch.
            drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,
                if the dataset size is not divisible by the batch size. If ``False`` and
                the size of dataset is not divisible by the batch size, then the last batch
                will be smaller. (default: ``False``)
            num_iterators (int): number of workers from which to retrieve data in parallel.
                num_iterators <= len(federated_dataset.workers) - 1
                the effect is to retrieve num_iterators epochs of data but at each step data
                from num_iterators distinct workers is returned.
            iter_per_worker (bool): if set to true, __next__() will return a dictionary
                containing one batch per worker
        """

        __initialized = False

        def __init__(
            self,
            federated_dataset,
            batch_size=8,
            shuffle=False,
            num_iterators=1,
            drop_last=False,
            collate_fn=default_collate,
            iter_per_worker=False,
            **kwargs,
        ):
            if len(kwargs) > 0:
                options = ", ".join([f"{k}: {v}" for k, v in kwargs.items()])
                logging.warning(f"The following options are not supported: {options}")

            try:
                self.workers = federated_dataset.workers
            except AttributeError:
                raise Exception(
                    "Your dataset is not a FederatedDataset, please use "
                    "torch.utils.data.DataLoader instead."
                )

            self.federated_dataset = federated_dataset
            self.batch_size = batch_size
            self.drop_last = drop_last
            self.collate_fn = collate_fn
            self.iter_class = _DataLoaderOneWorkerIter if iter_per_worker else _DataLoaderIter

            # Build a batch sampler per worker
            self.batch_samplers = {}
            for worker in self.workers:
                data_range = range(len(federated_dataset[worker]))
                if shuffle:
                    sampler = RandomSampler(data_range)
                else:
                    sampler = SequentialSampler(data_range)
                batch_sampler = BatchSampler(sampler, batch_size, drop_last)
                self.batch_samplers[worker] = batch_sampler

            if iter_per_worker:
                self.num_iterators = len(self.workers)
            else:
                # You can't have more iterators than n - 1 workers, because you always
                # need a worker idle in the worker switch process made by iterators
                if len(self.workers) == 1:
                    self.num_iterators = 1
                else:
                    self.num_iterators = min(num_iterators, len(self.workers) - 1)

        def __iter__(self):
            self.iterators = []
            for idx in range(self.num_iterators):
                self.iterators.append(self.iter_class(self, worker_idx=idx))
            return self

        def __next__(self):
            if self.num_iterators > 1:
                batches = {}
                for iterator in self.iterators:
                    data, target = next(iterator)
                    batches[data.location] = (data, target)
                return batches
            else:
                iterator = self.iterators[0]
                data, target = next(iterator)
                return data, target

        def __len__(self):
            length = len(self.federated_dataset) / self.batch_size
            if self.drop_last:
                return int(length)
            else:
                return math.ceil(length)
    ```

    - .federate() í•¨ìˆ˜ë¥¼ ì´ìš©í•´ federatedëœ ë°ì´í„°ì…‹ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.
- **torch.device**

    CUDA Tensors : `.to` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ Tensorë¥¼ ì–´ë– í•œ ì¥ì¹˜ë¡œë„ ì˜®ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ```python
    # ì´ ì½”ë“œëŠ” CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•œ í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    # ``torch.device`` ë¥¼ ì‚¬ìš©í•˜ì—¬ tensorë¥¼ GPU ì•ˆíŒìœ¼ë¡œ ì´ë™í•´ë³´ê² ìŠµë‹ˆë‹¤.
    if torch.cuda.is_available(): 
    	device = torch.device("cuda")         # CUDA ì¥ì¹˜ ê°ì²´(device object)ë¡œ 
    	y = torch.ones_like(x, device=device) # GPU ìƒì— ì§ì ‘ì ìœ¼ë¡œ tensorë¥¼ ìƒì„±í•˜ê±°ë‚˜
    	x = x.to(device)                      # ``.to("cuda")`` ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤. 
    	z = x + y 
    	print(z) 
    	print(z.to("cpu", torch.double))      # ``.to`` ëŠ” dtypeë„ í•¨ê»˜ ë³€ê²½í•©ë‹ˆë‹¤!
    ```

### í•´ê²°í•  ì¼

- [x]  ì¤‘ì•™ì¥ì¹˜ê°€ ì•„ë‹Œ ì›Œì»¤ê°€ ì†Œìœ í•œ ë°ì´í„°ë¥¼ ì´ìš©í•œ í•™ìŠµ
- [ ]
